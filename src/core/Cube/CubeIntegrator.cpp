#include "CubeIntegrator.hpp"
#include "TextureCommon.hpp"
#include "VK.hpp"

#include <stb_image.h>
#ifdef _MSC_VER
#pragma warning(push)
#pragma warning(disable: 4100 4244 4996)
#endif
#define STB_IMAGE_WRITE_IMPLEMENTATION
#include <stb_image_write.h>
#ifdef _MSC_VER
#pragma warning(pop)
#endif

#include <stdexcept>
#include <string>
#include <vector>
#include <cstring>
#include <iostream>

// -------------------------------------------------------------------------
// Compiled SPIR-V shaders (generated by Maek / glslc)
// -------------------------------------------------------------------------
static const uint32_t lambertian_spv[] = {
#include "../../shaders/spv/lambertian_integrate.comp.inl"
};
static const uint32_t ggx_spv[] = {
#include "../../shaders/spv/ggx_prefilter.comp.inl"
};

// -------------------------------------------------------------------------
CubeIntegrator::CubeIntegrator(RTG &rtg_) : rtg(rtg_) {
    // Command pool on the graphics queue (which also supports compute)
    VkCommandPoolCreateInfo pool_info{
        .sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO,
        .flags = VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT,
        .queueFamilyIndex = rtg.graphics_queue_family.value(),
    };
    VK(vkCreateCommandPool(rtg.device, &pool_info, nullptr, &command_pool));

    VkCommandBufferAllocateInfo alloc_info{
        .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO,
        .commandPool = command_pool,
        .level = VK_COMMAND_BUFFER_LEVEL_PRIMARY,
        .commandBufferCount = 1,
    };
    VK(vkAllocateCommandBuffers(rtg.device, &alloc_info, &command_buffer));

    VkFenceCreateInfo fence_info{
        .sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO,
        .flags = 0,
    };
    VK(vkCreateFence(rtg.device, &fence_info, nullptr, &fence));

    create_pipelines();
}

CubeIntegrator::~CubeIntegrator() {
    destroy_pipelines();

    vkDestroyFence(rtg.device, fence, nullptr);
    vkFreeCommandBuffers(rtg.device, command_pool, 1, &command_buffer);
    vkDestroyCommandPool(rtg.device, command_pool, nullptr);
}

// -------------------------------------------------------------------------
// Pipeline creation helpers
// -------------------------------------------------------------------------
static void create_compute_pipeline(
    VkDevice device,
    const uint32_t *spv, size_t spv_bytes,
    const VkDescriptorSetLayoutBinding *bindings, uint32_t binding_count,
    uint32_t push_constant_size,
    VkShaderModule &out_shader,
    VkDescriptorSetLayout &out_dsl,
    VkPipelineLayout &out_layout,
    VkPipeline &out_pipeline
) {
    // Shader module
    VkShaderModuleCreateInfo sm_info{
        .sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO,
        .codeSize = spv_bytes,
        .pCode = spv,
    };
    VK(vkCreateShaderModule(device, &sm_info, nullptr, &out_shader));

    // Descriptor set layout
    VkDescriptorSetLayoutCreateInfo dsl_info{
        .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO,
        .bindingCount = binding_count,
        .pBindings = bindings,
    };
    VK(vkCreateDescriptorSetLayout(device, &dsl_info, nullptr, &out_dsl));

    // Pipeline layout
    VkPushConstantRange pc_range{
        .stageFlags = VK_SHADER_STAGE_COMPUTE_BIT,
        .offset = 0,
        .size = push_constant_size,
    };
    VkPipelineLayoutCreateInfo pl_info{
        .sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO,
        .setLayoutCount = 1,
        .pSetLayouts = &out_dsl,
        .pushConstantRangeCount = (push_constant_size > 0) ? 1u : 0u,
        .pPushConstantRanges = (push_constant_size > 0) ? &pc_range : nullptr,
    };
    VK(vkCreatePipelineLayout(device, &pl_info, nullptr, &out_layout));

    // Compute pipeline
    VkComputePipelineCreateInfo cp_info{
        .sType = VK_STRUCTURE_TYPE_COMPUTE_PIPELINE_CREATE_INFO,
        .stage = {
            .sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO,
            .stage = VK_SHADER_STAGE_COMPUTE_BIT,
            .module = out_shader,
            .pName = "main",
        },
        .layout = out_layout,
    };
    VK(vkCreateComputePipelines(device, VK_NULL_HANDLE, 1, &cp_info, nullptr, &out_pipeline));
}

void CubeIntegrator::create_pipelines() {
    // --- Lambertian ---
    VkDescriptorSetLayoutBinding lamb_bindings[2] = {
        {   // binding 0: input sampler2DArray
            .binding = 0,
            .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
            .descriptorCount = 1,
            .stageFlags = VK_SHADER_STAGE_COMPUTE_BIT,
        },
        {   // binding 1: output storage image
            .binding = 1,
            .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
            .descriptorCount = 1,
            .stageFlags = VK_SHADER_STAGE_COMPUTE_BIT,
        },
    };
    create_compute_pipeline(
        rtg.device,
        lambertian_spv, sizeof(lambertian_spv),
        lamb_bindings, 2,
        0, // no push constants
        lambertian_shader, lambertian_descriptor_set_layout,
        lambertian_pipeline_layout, lambertian_pipeline
    );

    // --- GGX ---
    VkDescriptorSetLayoutBinding ggx_bindings[2] = {
        { .binding = 0, .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
          .descriptorCount = 1, .stageFlags = VK_SHADER_STAGE_COMPUTE_BIT },
        { .binding = 1, .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
          .descriptorCount = 1, .stageFlags = VK_SHADER_STAGE_COMPUTE_BIT },
    };
    create_compute_pipeline(
        rtg.device,
        ggx_spv, sizeof(ggx_spv),
        ggx_bindings, 2,
        sizeof(float), // push constant: roughness
        ggx_shader, ggx_descriptor_set_layout,
        ggx_pipeline_layout, ggx_pipeline
    );
}

void CubeIntegrator::destroy_pipelines() {
    vkDestroyPipeline(rtg.device, ggx_pipeline, nullptr);
    vkDestroyPipelineLayout(rtg.device, ggx_pipeline_layout, nullptr);
    vkDestroyDescriptorSetLayout(rtg.device, ggx_descriptor_set_layout, nullptr);
    vkDestroyShaderModule(rtg.device, ggx_shader, nullptr);

    vkDestroyPipeline(rtg.device, lambertian_pipeline, nullptr);
    vkDestroyPipelineLayout(rtg.device, lambertian_pipeline_layout, nullptr);
    vkDestroyDescriptorSetLayout(rtg.device, lambertian_descriptor_set_layout, nullptr);
    vkDestroyShaderModule(rtg.device, lambertian_shader, nullptr);
}

// -------------------------------------------------------------------------
// Load input cubemap
// -------------------------------------------------------------------------
CubeIntegrator::LoadedCubemap CubeIntegrator::load_input(const std::string &path) {
    int atlas_w, atlas_h, channels;
    stbi_set_flip_vertically_on_load(false);
    unsigned char *raw = stbi_load(path.c_str(), &atlas_w, &atlas_h, &channels, 4);
    if (!raw) {
        throw std::runtime_error("CubeIntegrator: failed to load '" + path + "': " +
                                 (stbi_failure_reason() ? stbi_failure_reason() : "unknown"));
    }

    const int face_size = atlas_w;
    if (atlas_h != face_size * 6) {
        stbi_image_free(raw);
        throw std::runtime_error("CubeIntegrator: atlas height must be 6x face_size. Got " +
                                 std::to_string(atlas_w) + "x" + std::to_string(atlas_h));
    }

    // Decode RGBE → float and flatten into a single float buffer (RGBA float, 6 faces)
    const size_t pixels_per_face = (size_t)face_size * face_size;
    std::vector<float> float_data(pixels_per_face * 6 * 4);

    for (int face = 0; face < 6; ++face) {
        for (int py = 0; py < face_size; ++py) {
            for (int px = 0; px < face_size; ++px) {
                // Row in atlas: face * face_size + py
                int src_row = face * face_size + py;
                const unsigned char *src = raw + (src_row * atlas_w + px) * 4;
                float *dst = float_data.data() + (face * pixels_per_face + py * face_size + px) * 4;
                decode_rgbe(src, dst);
            }
        }
    }
    stbi_image_free(raw);

    // Create image: is_cube=true yields 6 arrayLayers + VK_IMAGE_CREATE_CUBE_COMPATIBLE_BIT.
    // A VK_IMAGE_VIEW_TYPE_2D_ARRAY view is valid on a cube-compatible image.
    auto allocated_image = rtg.helpers.create_image(
        VkExtent2D{ (uint32_t)face_size, (uint32_t)face_size },
        VK_FORMAT_R32G32B32A32_SFLOAT,
        VK_IMAGE_TILING_OPTIMAL,
        VK_IMAGE_USAGE_SAMPLED_BIT | VK_IMAGE_USAGE_TRANSFER_DST_BIT,
        VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
        Helpers::Unmapped,
        true, 1
    );

    // transfer_to_image handles: staging buffer, memcpy, UNDEFINED->TRANSFER_DST->SHADER_READ_ONLY,
    // submit, and vkQueueWaitIdle. Uses helpers' own transfer_command_buffer — no conflict.
    // Data layout: face * face_size^2 * 16 bytes — identical to float_data's layout.
    size_t data_bytes = float_data.size() * sizeof(float);
    rtg.helpers.transfer_to_image(
        { static_cast<void*>(float_data.data()) },
        { data_bytes },
        allocated_image,
        6
    );

    VkImageView view = create_image_view(
        rtg.device, 
        allocated_image.handle,
        VK_FORMAT_R32G32B32A32_SFLOAT,
        true
    );

    VkSampler sampler = create_sampler(
        rtg.device, VK_FILTER_LINEAR,
        VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE,
        VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE,
        VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE,
        VK_BORDER_COLOR_FLOAT_TRANSPARENT_BLACK, 0.0f
    );

    LoadedCubemap result;
    result.image   = std::move(allocated_image);
    result.view    = view;
    result.sampler = sampler;
    result.face_size = (uint32_t)face_size;
    return result;
}

void CubeIntegrator::destroy_loaded_cubemap(LoadedCubemap &c) {
    vkDestroySampler(rtg.device, c.sampler, nullptr);
    vkDestroyImageView(rtg.device, c.view, nullptr);
    rtg.helpers.destroy_image(std::move(c.image));
}

// -------------------------------------------------------------------------
// Create output image
// -------------------------------------------------------------------------
CubeIntegrator::OutputImage CubeIntegrator::create_output(uint32_t face_size) {
    // Create image: is_cube=true yields 6 arrayLayers + VK_IMAGE_CREATE_CUBE_COMPATIBLE_BIT.
    auto allocated_image = rtg.helpers.create_image(
        VkExtent2D{ face_size, face_size },
        VK_FORMAT_R32G32B32A32_SFLOAT,
        VK_IMAGE_TILING_OPTIMAL,
        VK_IMAGE_USAGE_STORAGE_BIT | VK_IMAGE_USAGE_TRANSFER_SRC_BIT,
        VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
        Helpers::Unmapped,
        true, 1
    );

    // Transition to GENERAL for storage image use in compute shader.
    // transfer_to_image only transitions to SHADER_READ_ONLY, so use the helper for GENERAL layout.
    rtg.helpers.transition_image_layout(
        allocated_image.handle,
        VK_IMAGE_LAYOUT_UNDEFINED,
        VK_IMAGE_LAYOUT_GENERAL,
        1,  // mip levels
        6   // array layers (cubemap faces)
    );

    VkImageView view = create_image_view(
        rtg.device, 
        allocated_image.handle,
        VK_FORMAT_R32G32B32A32_SFLOAT,
        true
    );

    OutputImage result;
    result.image     = std::move(allocated_image);
    result.view      = view;
    result.face_size = face_size;
    return result;
}

void CubeIntegrator::destroy_output(OutputImage &o) {
    vkDestroyImageView(rtg.device, o.view, nullptr);
    rtg.helpers.destroy_image(std::move(o.image));
}

// -------------------------------------------------------------------------
// Readback and save
// -------------------------------------------------------------------------
void CubeIntegrator::readback_and_save(const OutputImage &out, const std::string &path) {
    uint32_t face_size = out.face_size;
    size_t pixels_per_face = (size_t)face_size * face_size;
    size_t total_floats = pixels_per_face * 6 * 4;
    size_t data_bytes = total_floats * sizeof(float);

    // Staging buffer (host-visible, host-coherent)
    auto staging = rtg.helpers.create_buffer(
        data_bytes,
        VK_BUFFER_USAGE_TRANSFER_DST_BIT,
        VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
        Helpers::Mapped
    );

    // Transition GENERAL -> TRANSFER_SRC for readback
    rtg.helpers.transition_image_layout(
        out.image.handle,
        VK_IMAGE_LAYOUT_GENERAL,
        VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL,
        1,  // mip levels
        6   // array layers (cubemap faces)
    );

    VkCommandBufferBeginInfo begin{ .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO,
                                    .flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT };
    VK(vkBeginCommandBuffer(command_buffer, &begin));

    for (int face = 0; face < 6; ++face) {
        VkBufferImageCopy copy{
            .bufferOffset = (VkDeviceSize)(face * pixels_per_face * 4 * sizeof(float)),
            .bufferRowLength = 0,
            .bufferImageHeight = 0,
            .imageSubresource = { VK_IMAGE_ASPECT_COLOR_BIT, 0, (uint32_t)face, 1 },
            .imageOffset = { 0, 0, 0 },
            .imageExtent = { face_size, face_size, 1 },
        };
        vkCmdCopyImageToBuffer(command_buffer, out.image.handle, VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL, staging.handle, 1, &copy);
    }

    VK(vkEndCommandBuffer(command_buffer));
    VkSubmitInfo submit{ .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,
                         .commandBufferCount = 1, .pCommandBuffers = &command_buffer };
    VK(vkQueueSubmit(rtg.graphics_queue, 1, &submit, fence));
    VK(vkWaitForFences(rtg.device, 1, &fence, VK_TRUE, UINT64_MAX));
    VK(vkResetFences(rtg.device, 1, &fence));
    VK(vkResetCommandBuffer(command_buffer, 0));

    // Encode to RGBE and write PNG atlas (width = face_size, height = face_size * 6)
    const float *floats = reinterpret_cast<const float *>(staging.allocation.data());
    std::vector<unsigned char> atlas((size_t)face_size * face_size * 6 * 4);

    for (int face = 0; face < 6; ++face) {
        for (uint32_t py = 0; py < face_size; ++py) {
            for (uint32_t px = 0; px < face_size; ++px) {
                const float *src = floats + (face * pixels_per_face + py * face_size + px) * 4;
                // Destination: row (face * face_size + py) in the atlas
                unsigned char *dst = atlas.data() +
                    ((face * face_size + py) * face_size + px) * 4;
                encode_rgbe(src[0], src[1], src[2], dst);
            }
        }
    }

    int ok = stbi_write_png(path.c_str(),
                            (int)face_size, (int)(face_size * 6),
                            4, atlas.data(), (int)(face_size * 4));
    if (!ok) {
        throw std::runtime_error("CubeIntegrator: failed to write '" + path + "'");
    }
    std::cout << "Wrote " << path << " (" << face_size << "x" << (face_size * 6) << ")\n";

    rtg.helpers.destroy_buffer(std::move(staging));
}

// -------------------------------------------------------------------------
// Dispatch helper
// -------------------------------------------------------------------------
void CubeIntegrator::dispatch_and_wait(
    VkPipeline pipeline,
    VkPipelineLayout layout,
    VkDescriptorSet descriptor_set,
    uint32_t groups_x, uint32_t groups_y, uint32_t groups_z,
    const void *push_constants,
    uint32_t push_constants_size
) {
    VkCommandBufferBeginInfo begin{ .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO,
                                    .flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT };
    VK(vkBeginCommandBuffer(command_buffer, &begin));
    vkCmdBindPipeline(command_buffer, VK_PIPELINE_BIND_POINT_COMPUTE, pipeline);
    vkCmdBindDescriptorSets(command_buffer, VK_PIPELINE_BIND_POINT_COMPUTE,
                            layout, 0, 1, &descriptor_set, 0, nullptr);
    if (push_constants && push_constants_size > 0) {
        vkCmdPushConstants(command_buffer, layout,
                           VK_SHADER_STAGE_COMPUTE_BIT, 0, push_constants_size, push_constants);
    }
    vkCmdDispatch(command_buffer, groups_x, groups_y, groups_z);
    VK(vkEndCommandBuffer(command_buffer));

    VkSubmitInfo submit{ .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,
                         .commandBufferCount = 1, .pCommandBuffers = &command_buffer };
    VK(vkQueueSubmit(rtg.graphics_queue, 1, &submit, fence));
    VK(vkWaitForFences(rtg.device, 1, &fence, VK_TRUE, UINT64_MAX));
    VK(vkResetFences(rtg.device, 1, &fence));
    VK(vkResetCommandBuffer(command_buffer, 0));
}

// -------------------------------------------------------------------------
// run_lambertian
// -------------------------------------------------------------------------
void CubeIntegrator::run_lambertian(const std::string &in_path, const std::string &out_path) {
    std::cout << "Lambertian integration: " << in_path << " -> " << out_path << "\n";

    auto input = load_input(in_path);
    auto output = create_output(32u);

    // Descriptor pool
    VkDescriptorPoolSize pool_sizes[2] = {
        { VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER, 1 },
        { VK_DESCRIPTOR_TYPE_STORAGE_IMAGE, 1 },
    };
    VkDescriptorPoolCreateInfo dp_info{
        .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO,
        .maxSets = 1,
        .poolSizeCount = 2,
        .pPoolSizes = pool_sizes,
    };
    VK(vkCreateDescriptorPool(rtg.device, &dp_info, nullptr, &descriptor_pool));

    VkDescriptorSetAllocateInfo ds_alloc{
        .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO,
        .descriptorPool = descriptor_pool,
        .descriptorSetCount = 1,
        .pSetLayouts = &lambertian_descriptor_set_layout,
    };
    VkDescriptorSet ds;
    VK(vkAllocateDescriptorSets(rtg.device, &ds_alloc, &ds));

    VkDescriptorImageInfo in_info{
        .sampler = input.sampler,
        .imageView = input.view,
        .imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL,
    };
    VkDescriptorImageInfo out_info{
        .imageView = output.view,
        .imageLayout = VK_IMAGE_LAYOUT_GENERAL,
    };
    VkWriteDescriptorSet writes[2] = {
        { .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET, .dstSet = ds, .dstBinding = 0,
          .descriptorCount = 1, .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
          .pImageInfo = &in_info },
        { .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET, .dstSet = ds, .dstBinding = 1,
          .descriptorCount = 1, .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
          .pImageInfo = &out_info },
    };
    vkUpdateDescriptorSets(rtg.device, 2, writes, 0, nullptr);

    // Dispatch: 8x8 local, 32x32 output, 6 faces
    uint32_t gx = (32 + 7) / 8;
    uint32_t gy = (32 + 7) / 8;
    dispatch_and_wait(lambertian_pipeline, lambertian_pipeline_layout, ds, gx, gy, 6);

    readback_and_save(output, out_path);

    vkDestroyDescriptorPool(rtg.device, descriptor_pool, nullptr);
    descriptor_pool = VK_NULL_HANDLE;

    destroy_output(output);
    destroy_loaded_cubemap(input);
}

// -------------------------------------------------------------------------
// run_ggx
// -------------------------------------------------------------------------
void CubeIntegrator::run_ggx(const std::string &in_path, const std::string &out_stem) {
    std::cout << "GGX pre-integration: " << in_path << " -> " << out_stem << ".{1..5}.png\n";

    auto input = load_input(in_path);

    // 5 mip levels: 512, 256, 128, 64, 32
    const uint32_t face_sizes[5] = { 512, 256, 128, 64, 32 };
    const float roughnesses[5]   = { 0.0f, 0.25f, 0.5f, 0.75f, 1.0f };

    for (int mip = 0; mip < 5; ++mip) {
        uint32_t fs = face_sizes[mip];
        float roughness = roughnesses[mip];
        std::string out_path = out_stem + "." + std::to_string(mip + 1) + ".png";
        std::cout << "  mip " << (mip + 1) << " (" << fs << "x" << fs
                  << ", roughness=" << roughness << ")...\n";

        auto output = create_output(fs);

        // Descriptor pool
        VkDescriptorPoolSize pool_sizes[2] = {
            { VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER, 1 },
            { VK_DESCRIPTOR_TYPE_STORAGE_IMAGE, 1 },
        };
        VkDescriptorPoolCreateInfo dp_info{
            .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO,
            .maxSets = 1,
            .poolSizeCount = 2,
            .pPoolSizes = pool_sizes,
        };
        VK(vkCreateDescriptorPool(rtg.device, &dp_info, nullptr, &descriptor_pool));

        VkDescriptorSetAllocateInfo ds_alloc{
            .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO,
            .descriptorPool = descriptor_pool,
            .descriptorSetCount = 1,
            .pSetLayouts = &ggx_descriptor_set_layout,
        };
        VkDescriptorSet ds;
        VK(vkAllocateDescriptorSets(rtg.device, &ds_alloc, &ds));

        VkDescriptorImageInfo in_info{
            .sampler = input.sampler,
            .imageView = input.view,
            .imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL,
        };
        VkDescriptorImageInfo out_info{
            .imageView = output.view,
            .imageLayout = VK_IMAGE_LAYOUT_GENERAL,
        };
        VkWriteDescriptorSet writes[2] = {
            { .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET, .dstSet = ds, .dstBinding = 0,
              .descriptorCount = 1, .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
              .pImageInfo = &in_info },
            { .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET, .dstSet = ds, .dstBinding = 1,
              .descriptorCount = 1, .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
              .pImageInfo = &out_info },
        };
        vkUpdateDescriptorSets(rtg.device, 2, writes, 0, nullptr);

        uint32_t gx = (fs + 7) / 8;
        uint32_t gy = (fs + 7) / 8;
        dispatch_and_wait(ggx_pipeline, ggx_pipeline_layout, ds, gx, gy, 6,
                          &roughness, sizeof(float));

        readback_and_save(output, out_path);

        vkDestroyDescriptorPool(rtg.device, descriptor_pool, nullptr);
        descriptor_pool = VK_NULL_HANDLE;
        destroy_output(output);
    }

    destroy_loaded_cubemap(input);
}

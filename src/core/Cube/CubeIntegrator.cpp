#include "CubeIntegrator.hpp"
#include "TextureCommon.hpp"
#include "VK.hpp"

#include <stb_image.h>
#ifdef _MSC_VER
#pragma warning(push)
#pragma warning(disable: 4100 4244 4996)
#endif
#define STB_IMAGE_WRITE_IMPLEMENTATION
#include <stb_image_write.h>
#ifdef _MSC_VER
#pragma warning(pop)
#endif

#include <stdexcept>
#include <string>
#include <vector>
#include <cstring>
#include <iostream>

// -------------------------------------------------------------------------
// Compiled SPIR-V shaders (generated by Maek / glslc)
// -------------------------------------------------------------------------
static const uint32_t lambertian_spv[] = {
#include "../../shaders/spv/lambertian_integrate.comp.inl"
};
static const uint32_t ggx_spv[] = {
#include "../../shaders/spv/ggx_prefilter.comp.inl"
};

// -------------------------------------------------------------------------
CubeIntegrator::CubeIntegrator(RTG &rtg_) : rtg(rtg_) {
    // Command pool on the graphics queue (which also supports compute)
    VkCommandPoolCreateInfo pool_info{
        .sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO,
        .flags = VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT,
        .queueFamilyIndex = rtg.graphics_queue_family.value(),
    };
    VK(vkCreateCommandPool(rtg.device, &pool_info, nullptr, &command_pool));

    VkCommandBufferAllocateInfo alloc_info{
        .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO,
        .commandPool = command_pool,
        .level = VK_COMMAND_BUFFER_LEVEL_PRIMARY,
        .commandBufferCount = 1,
    };
    VK(vkAllocateCommandBuffers(rtg.device, &alloc_info, &command_buffer));

    VkFenceCreateInfo fence_info{
        .sType = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO,
        .flags = 0,
    };
    VK(vkCreateFence(rtg.device, &fence_info, nullptr, &fence));

    create_pipelines();
}

CubeIntegrator::~CubeIntegrator() {
    destroy_pipelines();

    vkDestroyFence(rtg.device, fence, nullptr);
    vkFreeCommandBuffers(rtg.device, command_pool, 1, &command_buffer);
    vkDestroyCommandPool(rtg.device, command_pool, nullptr);
}

// -------------------------------------------------------------------------
// Pipeline creation helpers
// -------------------------------------------------------------------------
static void create_compute_pipeline(
    VkDevice device,
    const uint32_t *spv, size_t spv_bytes,
    const VkDescriptorSetLayoutBinding *bindings, uint32_t binding_count,
    uint32_t push_constant_size,
    VkShaderModule &out_shader,
    VkDescriptorSetLayout &out_dsl,
    VkPipelineLayout &out_layout,
    VkPipeline &out_pipeline
) {
    // Shader module
    VkShaderModuleCreateInfo sm_info{
        .sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO,
        .codeSize = spv_bytes,
        .pCode = spv,
    };
    VK(vkCreateShaderModule(device, &sm_info, nullptr, &out_shader));

    // Descriptor set layout
    VkDescriptorSetLayoutCreateInfo dsl_info{
        .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO,
        .bindingCount = binding_count,
        .pBindings = bindings,
    };
    VK(vkCreateDescriptorSetLayout(device, &dsl_info, nullptr, &out_dsl));

    // Pipeline layout
    VkPushConstantRange pc_range{
        .stageFlags = VK_SHADER_STAGE_COMPUTE_BIT,
        .offset = 0,
        .size = push_constant_size,
    };
    VkPipelineLayoutCreateInfo pl_info{
        .sType = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO,
        .setLayoutCount = 1,
        .pSetLayouts = &out_dsl,
        .pushConstantRangeCount = (push_constant_size > 0) ? 1u : 0u,
        .pPushConstantRanges = (push_constant_size > 0) ? &pc_range : nullptr,
    };
    VK(vkCreatePipelineLayout(device, &pl_info, nullptr, &out_layout));

    // Compute pipeline
    VkComputePipelineCreateInfo cp_info{
        .sType = VK_STRUCTURE_TYPE_COMPUTE_PIPELINE_CREATE_INFO,
        .stage = {
            .sType = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO,
            .stage = VK_SHADER_STAGE_COMPUTE_BIT,
            .module = out_shader,
            .pName = "main",
        },
        .layout = out_layout,
    };
    VK(vkCreateComputePipelines(device, VK_NULL_HANDLE, 1, &cp_info, nullptr, &out_pipeline));
}

void CubeIntegrator::create_pipelines() {
    // --- Lambertian ---
    VkDescriptorSetLayoutBinding lamb_bindings[2] = {
        {   // binding 0: input sampler2DArray
            .binding = 0,
            .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
            .descriptorCount = 1,
            .stageFlags = VK_SHADER_STAGE_COMPUTE_BIT,
        },
        {   // binding 1: output storage image
            .binding = 1,
            .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
            .descriptorCount = 1,
            .stageFlags = VK_SHADER_STAGE_COMPUTE_BIT,
        },
    };
    create_compute_pipeline(
        rtg.device,
        lambertian_spv, sizeof(lambertian_spv),
        lamb_bindings, 2,
        0, // no push constants
        lambertian_shader, lambertian_descriptor_set_layout,
        lambertian_pipeline_layout, lambertian_pipeline
    );

    // --- GGX ---
    VkDescriptorSetLayoutBinding ggx_bindings[2] = {
        { .binding = 0, .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
          .descriptorCount = 1, .stageFlags = VK_SHADER_STAGE_COMPUTE_BIT },
        { .binding = 1, .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
          .descriptorCount = 1, .stageFlags = VK_SHADER_STAGE_COMPUTE_BIT },
    };
    create_compute_pipeline(
        rtg.device,
        ggx_spv, sizeof(ggx_spv),
        ggx_bindings, 2,
        sizeof(float), // push constant: roughness
        ggx_shader, ggx_descriptor_set_layout,
        ggx_pipeline_layout, ggx_pipeline
    );
}

void CubeIntegrator::destroy_pipelines() {
    vkDestroyPipeline(rtg.device, ggx_pipeline, nullptr);
    vkDestroyPipelineLayout(rtg.device, ggx_pipeline_layout, nullptr);
    vkDestroyDescriptorSetLayout(rtg.device, ggx_descriptor_set_layout, nullptr);
    vkDestroyShaderModule(rtg.device, ggx_shader, nullptr);

    vkDestroyPipeline(rtg.device, lambertian_pipeline, nullptr);
    vkDestroyPipelineLayout(rtg.device, lambertian_pipeline_layout, nullptr);
    vkDestroyDescriptorSetLayout(rtg.device, lambertian_descriptor_set_layout, nullptr);
    vkDestroyShaderModule(rtg.device, lambertian_shader, nullptr);
}

// -------------------------------------------------------------------------
// Load input cubemap
// -------------------------------------------------------------------------
CubeIntegrator::LoadedCubemap CubeIntegrator::load_input(const std::string &path) {
    int atlas_w, atlas_h, channels;
    stbi_set_flip_vertically_on_load(false);
    unsigned char *raw = stbi_load(path.c_str(), &atlas_w, &atlas_h, &channels, 4);
    if (!raw) {
        throw std::runtime_error("CubeIntegrator: failed to load '" + path + "': " +
                                 (stbi_failure_reason() ? stbi_failure_reason() : "unknown"));
    }

    const int face_size = atlas_w;
    if (atlas_h != face_size * 6) {
        stbi_image_free(raw);
        throw std::runtime_error("CubeIntegrator: atlas height must be 6x face_size. Got " +
                                 std::to_string(atlas_w) + "x" + std::to_string(atlas_h));
    }

    // Decode RGBE â†’ float and flatten into a single float buffer (RGBA float, 6 faces)
    const size_t pixels_per_face = (size_t)face_size * face_size;
    std::vector<float> float_data(pixels_per_face * 6 * 4);

    for (int face = 0; face < 6; ++face) {
        for (int py = 0; py < face_size; ++py) {
            for (int px = 0; px < face_size; ++px) {
                // Row in atlas: face * face_size + py
                int src_row = face * face_size + py;
                const unsigned char *src = raw + (src_row * atlas_w + px) * 4;
                float *dst = float_data.data() + (face * pixels_per_face + py * face_size + px) * 4;
                decode_rgbe(src, dst);
            }
        }
    }
    stbi_image_free(raw);

    // Create VK_FORMAT_R32G32B32A32_SFLOAT image2DArray with 6 layers
    // We create a plain 2D-array image (not cube-compatible) for raw access.
    VkExtent2D extent{ (uint32_t)face_size, (uint32_t)face_size };

    // Staging buffer -> image transfer
    // Reuse helpers.transfer_to_image by treating it as a 1-mip 6-face cubemap upload.
    // (That function accepts face_count=6 and treats the image as a layered image.)
    // However the function expects VK_FORMAT_E5B9G9R9_UFLOAT_PACK32 and doesn't know about
    // float RGBA. We'll do the transfer manually below.

    // Create the image
    VkImageCreateInfo img_info{
        .sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO,
        .imageType = VK_IMAGE_TYPE_2D,
        .format = VK_FORMAT_R32G32B32A32_SFLOAT,
        .extent = { (uint32_t)face_size, (uint32_t)face_size, 1 },
        .mipLevels = 1,
        .arrayLayers = 6,
        .samples = VK_SAMPLE_COUNT_1_BIT,
        .tiling = VK_IMAGE_TILING_OPTIMAL,
        .usage = VK_IMAGE_USAGE_SAMPLED_BIT | VK_IMAGE_USAGE_TRANSFER_DST_BIT,
        .sharingMode = VK_SHARING_MODE_EXCLUSIVE,
        .initialLayout = VK_IMAGE_LAYOUT_UNDEFINED,
    };
    VkImage image;
    VK(vkCreateImage(rtg.device, &img_info, nullptr, &image));

    VkMemoryRequirements mem_req;
    vkGetImageMemoryRequirements(rtg.device, image, &mem_req);
    auto alloc = rtg.helpers.allocate(mem_req, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT);
    VK(vkBindImageMemory(rtg.device, image, alloc.handle, alloc.offset));

    // Staging buffer
    size_t data_bytes = float_data.size() * sizeof(float);
    auto staging = rtg.helpers.create_buffer(
        data_bytes,
        VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
        VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
        Helpers::Mapped
    );
    std::memcpy(staging.allocation.data(), float_data.data(), data_bytes);

    // Upload via command buffer
    VkCommandBufferBeginInfo begin{ .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO,
                                    .flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT };
    VK(vkBeginCommandBuffer(command_buffer, &begin));

    // Transition to TRANSFER_DST
    VkImageMemoryBarrier barrier{
        .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER,
        .srcAccessMask = 0,
        .dstAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT,
        .oldLayout = VK_IMAGE_LAYOUT_UNDEFINED,
        .newLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
        .srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED,
        .dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED,
        .image = image,
        .subresourceRange = { VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 6 },
    };
    vkCmdPipelineBarrier(command_buffer,
        VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT, VK_PIPELINE_STAGE_TRANSFER_BIT,
        0, 0, nullptr, 0, nullptr, 1, &barrier);

    // Copy each face
    for (int face = 0; face < 6; ++face) {
        VkBufferImageCopy copy{
            .bufferOffset = (VkDeviceSize)(face * pixels_per_face * 4 * sizeof(float)),
            .bufferRowLength = 0,
            .bufferImageHeight = 0,
            .imageSubresource = { VK_IMAGE_ASPECT_COLOR_BIT, 0, (uint32_t)face, 1 },
            .imageOffset = { 0, 0, 0 },
            .imageExtent = { (uint32_t)face_size, (uint32_t)face_size, 1 },
        };
        vkCmdCopyBufferToImage(command_buffer, staging.handle, image,
            VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL, 1, &copy);
    }

    // Transition to SHADER_READ_ONLY
    barrier.srcAccessMask = VK_ACCESS_TRANSFER_WRITE_BIT;
    barrier.dstAccessMask = VK_ACCESS_SHADER_READ_BIT;
    barrier.oldLayout = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL;
    barrier.newLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL;
    vkCmdPipelineBarrier(command_buffer,
        VK_PIPELINE_STAGE_TRANSFER_BIT, VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT,
        0, 0, nullptr, 0, nullptr, 1, &barrier);

    VK(vkEndCommandBuffer(command_buffer));

    VkSubmitInfo submit{ .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,
                         .commandBufferCount = 1, .pCommandBuffers = &command_buffer };
    VK(vkQueueSubmit(rtg.graphics_queue, 1, &submit, fence));
    VK(vkWaitForFences(rtg.device, 1, &fence, VK_TRUE, UINT64_MAX));
    VK(vkResetFences(rtg.device, 1, &fence));
    VK(vkResetCommandBuffer(command_buffer, 0));

    rtg.helpers.destroy_buffer(std::move(staging));

    // Image view (2DArray, 6 layers)
    VkImageViewCreateInfo view_info{
        .sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO,
        .image = image,
        .viewType = VK_IMAGE_VIEW_TYPE_2D_ARRAY,
        .format = VK_FORMAT_R32G32B32A32_SFLOAT,
        .subresourceRange = { VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 6 },
    };
    VkImageView view;
    VK(vkCreateImageView(rtg.device, &view_info, nullptr, &view));

    VkSamplerCreateInfo sampler_info{
        .sType = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO,
        .magFilter = VK_FILTER_LINEAR,
        .minFilter = VK_FILTER_LINEAR,
        .mipmapMode = VK_SAMPLER_MIPMAP_MODE_LINEAR,
        .addressModeU = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE,
        .addressModeV = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE,
        .addressModeW = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE,
        .maxLod = 0.0f,
    };
    VkSampler sampler;
    VK(vkCreateSampler(rtg.device, &sampler_info, nullptr, &sampler));

    // Package into AllocatedImage-like struct
    LoadedCubemap result;
    result.image.handle = image;
    result.image.extent = extent;
    result.image.format = VK_FORMAT_R32G32B32A32_SFLOAT;
    result.image.allocation = std::move(alloc);
    result.view = view;
    result.sampler = sampler;
    result.face_size = (uint32_t)face_size;
    return result;
}

void CubeIntegrator::destroy_loaded_cubemap(LoadedCubemap &c) {
    vkDestroySampler(rtg.device, c.sampler, nullptr);
    vkDestroyImageView(rtg.device, c.view, nullptr);
    vkDestroyImage(rtg.device, c.image.handle, nullptr);
    rtg.helpers.free(std::move(c.image.allocation));
    c.image.handle = VK_NULL_HANDLE;
}

// -------------------------------------------------------------------------
// Create output image
// -------------------------------------------------------------------------
CubeIntegrator::OutputImage CubeIntegrator::create_output(uint32_t face_size) {
    VkImageCreateInfo img_info{
        .sType = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO,
        .imageType = VK_IMAGE_TYPE_2D,
        .format = VK_FORMAT_R32G32B32A32_SFLOAT,
        .extent = { face_size, face_size, 1 },
        .mipLevels = 1,
        .arrayLayers = 6,
        .samples = VK_SAMPLE_COUNT_1_BIT,
        .tiling = VK_IMAGE_TILING_OPTIMAL,
        .usage = VK_IMAGE_USAGE_STORAGE_BIT | VK_IMAGE_USAGE_TRANSFER_SRC_BIT,
        .sharingMode = VK_SHARING_MODE_EXCLUSIVE,
        .initialLayout = VK_IMAGE_LAYOUT_UNDEFINED,
    };
    VkImage image;
    VK(vkCreateImage(rtg.device, &img_info, nullptr, &image));

    VkMemoryRequirements mem_req;
    vkGetImageMemoryRequirements(rtg.device, image, &mem_req);
    auto alloc = rtg.helpers.allocate(mem_req, VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT);
    VK(vkBindImageMemory(rtg.device, image, alloc.handle, alloc.offset));

    // Transition to GENERAL for storage image
    VkCommandBufferBeginInfo begin{ .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO,
                                    .flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT };
    VK(vkBeginCommandBuffer(command_buffer, &begin));
    VkImageMemoryBarrier barrier{
        .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER,
        .srcAccessMask = 0,
        .dstAccessMask = VK_ACCESS_SHADER_WRITE_BIT,
        .oldLayout = VK_IMAGE_LAYOUT_UNDEFINED,
        .newLayout = VK_IMAGE_LAYOUT_GENERAL,
        .srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED,
        .dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED,
        .image = image,
        .subresourceRange = { VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 6 },
    };
    vkCmdPipelineBarrier(command_buffer,
        VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT, VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT,
        0, 0, nullptr, 0, nullptr, 1, &barrier);
    VK(vkEndCommandBuffer(command_buffer));

    VkSubmitInfo submit{ .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,
                         .commandBufferCount = 1, .pCommandBuffers = &command_buffer };
    VK(vkQueueSubmit(rtg.graphics_queue, 1, &submit, fence));
    VK(vkWaitForFences(rtg.device, 1, &fence, VK_TRUE, UINT64_MAX));
    VK(vkResetFences(rtg.device, 1, &fence));
    VK(vkResetCommandBuffer(command_buffer, 0));

    VkImageViewCreateInfo view_info{
        .sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO,
        .image = image,
        .viewType = VK_IMAGE_VIEW_TYPE_2D_ARRAY,
        .format = VK_FORMAT_R32G32B32A32_SFLOAT,
        .subresourceRange = { VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 6 },
    };
    VkImageView view;
    VK(vkCreateImageView(rtg.device, &view_info, nullptr, &view));

    OutputImage result;
    result.image.handle = image;
    result.image.extent = { face_size, face_size };
    result.image.format = VK_FORMAT_R32G32B32A32_SFLOAT;
    result.image.allocation = std::move(alloc);
    result.view = view;
    result.face_size = face_size;
    return result;
}

void CubeIntegrator::destroy_output(OutputImage &o) {
    vkDestroyImageView(rtg.device, o.view, nullptr);
    vkDestroyImage(rtg.device, o.image.handle, nullptr);
    rtg.helpers.free(std::move(o.image.allocation));
    o.image.handle = VK_NULL_HANDLE;
}

// -------------------------------------------------------------------------
// Readback and save
// -------------------------------------------------------------------------
void CubeIntegrator::readback_and_save(const OutputImage &out, const std::string &path) {
    uint32_t face_size = out.face_size;
    size_t pixels_per_face = (size_t)face_size * face_size;
    size_t total_floats = pixels_per_face * 6 * 4;
    size_t data_bytes = total_floats * sizeof(float);

    // Staging buffer (host-visible, host-coherent)
    auto staging = rtg.helpers.create_buffer(
        data_bytes,
        VK_BUFFER_USAGE_TRANSFER_DST_BIT,
        VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
        Helpers::Mapped
    );

    VkCommandBufferBeginInfo begin{ .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO,
                                    .flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT };
    VK(vkBeginCommandBuffer(command_buffer, &begin));

    // Transition GENERAL -> TRANSFER_SRC
    VkImageMemoryBarrier barrier{
        .sType = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER,
        .srcAccessMask = VK_ACCESS_SHADER_WRITE_BIT,
        .dstAccessMask = VK_ACCESS_TRANSFER_READ_BIT,
        .oldLayout = VK_IMAGE_LAYOUT_GENERAL,
        .newLayout = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL,
        .srcQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED,
        .dstQueueFamilyIndex = VK_QUEUE_FAMILY_IGNORED,
        .image = out.image.handle,
        .subresourceRange = { VK_IMAGE_ASPECT_COLOR_BIT, 0, 1, 0, 6 },
    };
    vkCmdPipelineBarrier(command_buffer,
        VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT, VK_PIPELINE_STAGE_TRANSFER_BIT,
        0, 0, nullptr, 0, nullptr, 1, &barrier);

    for (int face = 0; face < 6; ++face) {
        VkBufferImageCopy copy{
            .bufferOffset = (VkDeviceSize)(face * pixels_per_face * 4 * sizeof(float)),
            .bufferRowLength = 0,
            .bufferImageHeight = 0,
            .imageSubresource = { VK_IMAGE_ASPECT_COLOR_BIT, 0, (uint32_t)face, 1 },
            .imageOffset = { 0, 0, 0 },
            .imageExtent = { face_size, face_size, 1 },
        };
        vkCmdCopyImageToBuffer(command_buffer, out.image.handle,
            VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL, staging.handle, 1, &copy);
    }

    VK(vkEndCommandBuffer(command_buffer));
    VkSubmitInfo submit{ .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,
                         .commandBufferCount = 1, .pCommandBuffers = &command_buffer };
    VK(vkQueueSubmit(rtg.graphics_queue, 1, &submit, fence));
    VK(vkWaitForFences(rtg.device, 1, &fence, VK_TRUE, UINT64_MAX));
    VK(vkResetFences(rtg.device, 1, &fence));
    VK(vkResetCommandBuffer(command_buffer, 0));

    // Encode to RGBE and write PNG atlas (width = face_size, height = face_size * 6)
    const float *floats = reinterpret_cast<const float *>(staging.allocation.data());
    std::vector<unsigned char> atlas((size_t)face_size * face_size * 6 * 4);

    for (int face = 0; face < 6; ++face) {
        for (uint32_t py = 0; py < face_size; ++py) {
            for (uint32_t px = 0; px < face_size; ++px) {
                const float *src = floats + (face * pixels_per_face + py * face_size + px) * 4;
                // Destination: row (face * face_size + py) in the atlas
                unsigned char *dst = atlas.data() +
                    ((face * face_size + py) * face_size + px) * 4;
                encode_rgbe(src[0], src[1], src[2], dst);
            }
        }
    }

    int ok = stbi_write_png(path.c_str(),
                            (int)face_size, (int)(face_size * 6),
                            4, atlas.data(), (int)(face_size * 4));
    if (!ok) {
        throw std::runtime_error("CubeIntegrator: failed to write '" + path + "'");
    }
    std::cout << "Wrote " << path << " (" << face_size << "x" << (face_size * 6) << ")\n";

    rtg.helpers.destroy_buffer(std::move(staging));
}

// -------------------------------------------------------------------------
// Dispatch helper
// -------------------------------------------------------------------------
void CubeIntegrator::dispatch_and_wait(
    VkPipeline pipeline,
    VkPipelineLayout layout,
    VkDescriptorSet descriptor_set,
    uint32_t groups_x, uint32_t groups_y, uint32_t groups_z,
    const void *push_constants,
    uint32_t push_constants_size
) {
    VkCommandBufferBeginInfo begin{ .sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO,
                                    .flags = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT };
    VK(vkBeginCommandBuffer(command_buffer, &begin));
    vkCmdBindPipeline(command_buffer, VK_PIPELINE_BIND_POINT_COMPUTE, pipeline);
    vkCmdBindDescriptorSets(command_buffer, VK_PIPELINE_BIND_POINT_COMPUTE,
                            layout, 0, 1, &descriptor_set, 0, nullptr);
    if (push_constants && push_constants_size > 0) {
        vkCmdPushConstants(command_buffer, layout,
                           VK_SHADER_STAGE_COMPUTE_BIT, 0, push_constants_size, push_constants);
    }
    vkCmdDispatch(command_buffer, groups_x, groups_y, groups_z);
    VK(vkEndCommandBuffer(command_buffer));

    VkSubmitInfo submit{ .sType = VK_STRUCTURE_TYPE_SUBMIT_INFO,
                         .commandBufferCount = 1, .pCommandBuffers = &command_buffer };
    VK(vkQueueSubmit(rtg.graphics_queue, 1, &submit, fence));
    VK(vkWaitForFences(rtg.device, 1, &fence, VK_TRUE, UINT64_MAX));
    VK(vkResetFences(rtg.device, 1, &fence));
    VK(vkResetCommandBuffer(command_buffer, 0));
}

// -------------------------------------------------------------------------
// run_lambertian
// -------------------------------------------------------------------------
void CubeIntegrator::run_lambertian(const std::string &in_path, const std::string &out_path) {
    std::cout << "Lambertian integration: " << in_path << " -> " << out_path << "\n";

    auto input = load_input(in_path);
    auto output = create_output(32u);

    // Descriptor pool
    VkDescriptorPoolSize pool_sizes[2] = {
        { VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER, 1 },
        { VK_DESCRIPTOR_TYPE_STORAGE_IMAGE, 1 },
    };
    VkDescriptorPoolCreateInfo dp_info{
        .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO,
        .maxSets = 1,
        .poolSizeCount = 2,
        .pPoolSizes = pool_sizes,
    };
    VK(vkCreateDescriptorPool(rtg.device, &dp_info, nullptr, &descriptor_pool));

    VkDescriptorSetAllocateInfo ds_alloc{
        .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO,
        .descriptorPool = descriptor_pool,
        .descriptorSetCount = 1,
        .pSetLayouts = &lambertian_descriptor_set_layout,
    };
    VkDescriptorSet ds;
    VK(vkAllocateDescriptorSets(rtg.device, &ds_alloc, &ds));

    VkDescriptorImageInfo in_info{
        .sampler = input.sampler,
        .imageView = input.view,
        .imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL,
    };
    VkDescriptorImageInfo out_info{
        .imageView = output.view,
        .imageLayout = VK_IMAGE_LAYOUT_GENERAL,
    };
    VkWriteDescriptorSet writes[2] = {
        { .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET, .dstSet = ds, .dstBinding = 0,
          .descriptorCount = 1, .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
          .pImageInfo = &in_info },
        { .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET, .dstSet = ds, .dstBinding = 1,
          .descriptorCount = 1, .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
          .pImageInfo = &out_info },
    };
    vkUpdateDescriptorSets(rtg.device, 2, writes, 0, nullptr);

    // Dispatch: 8x8 local, 32x32 output, 6 faces
    uint32_t gx = (32 + 7) / 8;
    uint32_t gy = (32 + 7) / 8;
    dispatch_and_wait(lambertian_pipeline, lambertian_pipeline_layout, ds, gx, gy, 6);

    readback_and_save(output, out_path);

    vkDestroyDescriptorPool(rtg.device, descriptor_pool, nullptr);
    descriptor_pool = VK_NULL_HANDLE;

    destroy_output(output);
    destroy_loaded_cubemap(input);
}

// -------------------------------------------------------------------------
// run_ggx
// -------------------------------------------------------------------------
void CubeIntegrator::run_ggx(const std::string &in_path, const std::string &out_stem) {
    std::cout << "GGX pre-integration: " << in_path << " -> " << out_stem << ".{1..5}.png\n";

    auto input = load_input(in_path);

    // 5 mip levels: 512, 256, 128, 64, 32
    const uint32_t face_sizes[5] = { 512, 256, 128, 64, 32 };
    const float roughnesses[5]   = { 0.0f, 0.25f, 0.5f, 0.75f, 1.0f };

    for (int mip = 0; mip < 5; ++mip) {
        uint32_t fs = face_sizes[mip];
        float roughness = roughnesses[mip];
        std::string out_path = out_stem + "." + std::to_string(mip + 1) + ".png";
        std::cout << "  mip " << (mip + 1) << " (" << fs << "x" << fs
                  << ", roughness=" << roughness << ")...\n";

        auto output = create_output(fs);

        // Descriptor pool
        VkDescriptorPoolSize pool_sizes[2] = {
            { VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER, 1 },
            { VK_DESCRIPTOR_TYPE_STORAGE_IMAGE, 1 },
        };
        VkDescriptorPoolCreateInfo dp_info{
            .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO,
            .maxSets = 1,
            .poolSizeCount = 2,
            .pPoolSizes = pool_sizes,
        };
        VK(vkCreateDescriptorPool(rtg.device, &dp_info, nullptr, &descriptor_pool));

        VkDescriptorSetAllocateInfo ds_alloc{
            .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO,
            .descriptorPool = descriptor_pool,
            .descriptorSetCount = 1,
            .pSetLayouts = &ggx_descriptor_set_layout,
        };
        VkDescriptorSet ds;
        VK(vkAllocateDescriptorSets(rtg.device, &ds_alloc, &ds));

        VkDescriptorImageInfo in_info{
            .sampler = input.sampler,
            .imageView = input.view,
            .imageLayout = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL,
        };
        VkDescriptorImageInfo out_info{
            .imageView = output.view,
            .imageLayout = VK_IMAGE_LAYOUT_GENERAL,
        };
        VkWriteDescriptorSet writes[2] = {
            { .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET, .dstSet = ds, .dstBinding = 0,
              .descriptorCount = 1, .descriptorType = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
              .pImageInfo = &in_info },
            { .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET, .dstSet = ds, .dstBinding = 1,
              .descriptorCount = 1, .descriptorType = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
              .pImageInfo = &out_info },
        };
        vkUpdateDescriptorSets(rtg.device, 2, writes, 0, nullptr);

        uint32_t gx = (fs + 7) / 8;
        uint32_t gy = (fs + 7) / 8;
        dispatch_and_wait(ggx_pipeline, ggx_pipeline_layout, ds, gx, gy, 6,
                          &roughness, sizeof(float));

        readback_and_save(output, out_path);

        vkDestroyDescriptorPool(rtg.device, descriptor_pool, nullptr);
        descriptor_pool = VK_NULL_HANDLE;
        destroy_output(output);
    }

    destroy_loaded_cubemap(input);
}
